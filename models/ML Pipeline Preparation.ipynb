{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Essam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Essam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Essam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import datetime\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, fbeta_score, classification_report\n",
    "from scipy.stats.mstats import gmean\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table('df', engine)\n",
    "X = df['message']\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1318     after how muche time does the earthquake stop?...\n",
       "11896    That was three in the last half hour a 7.2 and...\n",
       "14178    Lutheran World Relief is channeling funds thro...\n",
       "17896    Vietnam's Red River Delta region is vulnerable...\n",
       "4610     We don't have water, food, and shelter. we fou...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check data\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "      <th>direct</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        0      0            1             0                 0   \n",
       "2        0      0            0             0                 0   \n",
       "3        1      0            1             0                 1   \n",
       "4        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  water  ...  \\\n",
       "0                  0         0         0            0      0  ...   \n",
       "1                  0         0         0            0      0  ...   \n",
       "2                  0         0         0            0      0  ...   \n",
       "3                  0         0         0            0      0  ...   \n",
       "4                  0         0         0            0      0  ...   \n",
       "\n",
       "   weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "0                0       0      0     0           0     0              0   \n",
       "1                1       0      1     0           0     0              0   \n",
       "2                0       0      0     0           0     0              0   \n",
       "3                0       0      0     0           0     0              0   \n",
       "4                0       0      0     0           0     0              0   \n",
       "\n",
       "   direct_report  direct  news  \n",
       "0              0       1     0  \n",
       "1              0       1     0  \n",
       "2              0       1     0  \n",
       "3              0       1     0  \n",
       "4              0       1     0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check data\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text:', u'Is the Hurricane over or is it not over', '\\ntokens:', [u'is', u'the', u'hurricane', u'over', u'or', u'is', u'it', u'not', u'over'])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(\"text:\",X[1],\"\\ntokens:\", tokenize(X[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenize)), #create the CountVectorizer object\n",
    "    ('tfidf', TfidfTransformer()), #create Tfidftransformer object    \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(), n_jobs=-1)) #create RandomForestClassifier\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Essam\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training of Pipeline Done..., Time: 1', 'minutes')\n"
     ]
    }
   ],
   "source": [
    "#to calculate the time of running the train\n",
    "start_time  = datetime.datetime.now()\n",
    "#perform train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), Y.as_matrix(), test_size=0.2, random_state=42)\n",
    "#Train pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "end_time = datetime.datetime.now()\n",
    "print ('Training of Pipeline Done..., Time: %d' % ((end_time - start_time).seconds/60),'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the classifier\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert prediction numpy into dataframe\n",
    "y_test=pd.DataFrame(data=y_test,columns=Y.columns)\n",
    "y_pred=pd.DataFrame(data=y_pred,columns=Y.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEFINE GRIDSEARCH SCORING TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multioutput_fscore(y_true,y_pred,beta=1):\n",
    "    score_list = []\n",
    "    if isinstance(y_pred, pd.DataFrame) == True:\n",
    "        y_pred = y_pred.values\n",
    "    if isinstance(y_true, pd.DataFrame) == True:\n",
    "        y_true = y_true.values\n",
    "    for column in range(0,y_true.shape[1]):\n",
    "        score = fbeta_score(y_true[:,column],y_pred[:,column],beta,average='weighted')\n",
    "        score_list.append(score)\n",
    "    f1score_numpy = np.asarray(score_list)\n",
    "    f1score_numpy = f1score_numpy[f1score_numpy<1]\n",
    "    f1score = gmean(f1score_numpy)\n",
    "    return  f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall accuracy 94.64% \n",
      "\n",
      "F1 score (custom definition) 92.93%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Essam\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "multi_f1 = multioutput_fscore(y_test,y_pred, beta = 1)\n",
    "overall_accuracy = (y_pred == y_test).mean().mean()\n",
    "\n",
    "print('Average overall accuracy {0:.2f}% \\n'.format(overall_accuracy*100))\n",
    "print('F1 score (custom definition) {0:.2f}%\\n'.format(multi_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:\\n', request                   0.878719\n",
      "offer                     0.995042\n",
      "aid_related               0.733028\n",
      "medical_help              0.919336\n",
      "medical_products          0.952136\n",
      "search_and_rescue         0.975591\n",
      "security                  0.982838\n",
      "military                  0.971014\n",
      "child_alone               1.000000\n",
      "water                     0.944317\n",
      "food                      0.918383\n",
      "shelter                   0.924867\n",
      "clothing                  0.986651\n",
      "money                     0.980931\n",
      "missing_people            0.988558\n",
      "refugees                  0.967963\n",
      "death                     0.958429\n",
      "other_aid                 0.868230\n",
      "infrastructure_related    0.937071\n",
      "transport                 0.955378\n",
      "buildings                 0.951182\n",
      "electricity               0.977689\n",
      "tools                     0.993898\n",
      "hospitals                 0.990847\n",
      "shops                     0.995805\n",
      "aid_centers               0.987223\n",
      "other_infrastructure      0.956903\n",
      "weather_related           0.840961\n",
      "floods                    0.943745\n",
      "storm                     0.930778\n",
      "fire                      0.990084\n",
      "earthquake                0.945080\n",
      "cold                      0.978833\n",
      "other_weather             0.948703\n",
      "direct_report             0.851068\n",
      "direct                    0.939169\n",
      "news                      0.957094\n",
      "dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "print(\"Accuracy:\\n\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      4349\n",
      "           1       0.82      0.37      0.51       895\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5244\n",
      "   macro avg       0.85      0.68      0.72      5244\n",
      "weighted avg       0.87      0.88      0.86      5244\n",
      "\n",
      "_____________________________________________________\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5218\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80      3113\n",
      "           1       0.75      0.51      0.61      2131\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5244\n",
      "   macro avg       0.74      0.70      0.70      5244\n",
      "weighted avg       0.74      0.73      0.72      5244\n",
      "\n",
      "_____________________________________________________\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      4822\n",
      "           1       0.49      0.07      0.13       422\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      5244\n",
      "   macro avg       0.71      0.53      0.54      5244\n",
      "weighted avg       0.89      0.92      0.89      5244\n",
      "\n",
      "_____________________________________________________\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4974\n",
      "           1       0.76      0.10      0.18       270\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.86      0.55      0.58      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Essam\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5117\n",
      "           1       0.43      0.02      0.04       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.70      0.51      0.52      5244\n",
      "weighted avg       0.96      0.98      0.96      5244\n",
      "\n",
      "_____________________________________________________\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5156\n",
      "           1       0.25      0.01      0.02        88\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.62      0.51      0.51      5244\n",
      "weighted avg       0.97      0.98      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5089\n",
      "           1       0.59      0.06      0.12       155\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.78      0.53      0.55      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "_____________________________________________________\n",
      "child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5244\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       1.00      1.00      1.00      5244\n",
      "weighted avg       1.00      1.00      1.00      5244\n",
      "\n",
      "_____________________________________________________\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4905\n",
      "           1       0.80      0.19      0.30       339\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.87      0.59      0.64      5244\n",
      "weighted avg       0.94      0.94      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      4649\n",
      "           1       0.83      0.35      0.49       595\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      5244\n",
      "   macro avg       0.88      0.67      0.72      5244\n",
      "weighted avg       0.91      0.92      0.90      5244\n",
      "\n",
      "_____________________________________________________\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4774\n",
      "           1       0.87      0.19      0.31       470\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      5244\n",
      "   macro avg       0.90      0.59      0.64      5244\n",
      "weighted avg       0.92      0.92      0.90      5244\n",
      "\n",
      "_____________________________________________________\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5171\n",
      "           1       0.64      0.10      0.17        73\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.81      0.55      0.58      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5140\n",
      "           1       0.67      0.08      0.14       104\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.82      0.54      0.56      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5184\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5073\n",
      "           1       0.71      0.03      0.06       171\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.84      0.51      0.52      5244\n",
      "weighted avg       0.96      0.97      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5007\n",
      "           1       0.85      0.10      0.17       237\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.91      0.55      0.58      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4549\n",
      "           1       0.55      0.03      0.06       695\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5244\n",
      "   macro avg       0.71      0.51      0.50      5244\n",
      "weighted avg       0.83      0.87      0.81      5244\n",
      "\n",
      "_____________________________________________________\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4916\n",
      "           1       0.25      0.00      0.01       328\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.59      0.50      0.49      5244\n",
      "weighted avg       0.89      0.94      0.91      5244\n",
      "\n",
      "_____________________________________________________\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5004\n",
      "           1       0.62      0.06      0.11       240\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.79      0.53      0.55      5244\n",
      "weighted avg       0.94      0.96      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4977\n",
      "           1       0.74      0.06      0.12       267\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.85      0.53      0.55      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5122\n",
      "           1       1.00      0.04      0.08       122\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.99      0.52      0.53      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5212\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5198\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5222\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5177\n",
      "           1       0.00      0.00      0.00        67\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.97      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5021\n",
      "           1       0.20      0.00      0.01       223\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.58      0.50      0.49      5244\n",
      "weighted avg       0.93      0.96      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      3806\n",
      "           1       0.85      0.51      0.64      1438\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5244\n",
      "   macro avg       0.85      0.74      0.77      5244\n",
      "weighted avg       0.84      0.84      0.83      5244\n",
      "\n",
      "_____________________________________________________\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4833\n",
      "           1       0.91      0.31      0.47       411\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.93      0.66      0.72      5244\n",
      "weighted avg       0.94      0.94      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      4758\n",
      "           1       0.75      0.38      0.51       486\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5244\n",
      "   macro avg       0.84      0.69      0.74      5244\n",
      "weighted avg       0.92      0.93      0.92      5244\n",
      "\n",
      "_____________________________________________________\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5191\n",
      "           1       1.00      0.02      0.04        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       1.00      0.51      0.52      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4766\n",
      "           1       0.88      0.46      0.61       478\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.91      0.73      0.79      5244\n",
      "weighted avg       0.94      0.95      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5127\n",
      "           1       0.80      0.07      0.13       117\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.89      0.53      0.56      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4968\n",
      "           1       0.77      0.04      0.07       276\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.86      0.52      0.52      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91      4223\n",
      "           1       0.80      0.31      0.45      1021\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5244\n",
      "   macro avg       0.83      0.65      0.68      5244\n",
      "weighted avg       0.84      0.85      0.82      5244\n",
      "\n",
      "_____________________________________________________\n",
      "direct\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3067\n",
      "           1       0.93      0.93      0.93      2177\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.94      0.94      0.94      5244\n",
      "weighted avg       0.94      0.94      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "news\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2670\n",
      "           1       0.98      0.94      0.96      2574\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.96      0.96      0.96      5244\n",
      "weighted avg       0.96      0.96      0.96      5244\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "results_dic1={}\n",
    "for column in y_pred.columns:\n",
    "    print(column)\n",
    "    print(classification_report(y_test[column], y_pred[column]))\n",
    "    print('_____________________________________________________')\n",
    "\n",
    "    results_dic1[column]=classification_report(y_test[column], y_pred[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "      <th>direct</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        0      0            0             0                 0   \n",
       "2        0      0            1             0                 0   \n",
       "3        0      0            0             0                 0   \n",
       "4        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  water  ...  \\\n",
       "0                  0         0         0            0      0  ...   \n",
       "1                  0         0         0            0      0  ...   \n",
       "2                  0         0         0            0      0  ...   \n",
       "3                  0         0         0            0      0  ...   \n",
       "4                  0         0         0            0      0  ...   \n",
       "\n",
       "   weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "0                0       0      0     0           0     0              0   \n",
       "1                0       0      0     0           0     0              0   \n",
       "2                0       0      0     0           0     0              0   \n",
       "3                0       0      0     0           0     0              0   \n",
       "4                0       0      0     0           0     0              0   \n",
       "\n",
       "   direct_report  direct  news  \n",
       "0              0       1     0  \n",
       "1              0       0     1  \n",
       "2              0       0     1  \n",
       "3              0       0     1  \n",
       "4              0       1     0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get names of all categories\n",
    "category_names = y_test.columns.tolist()\n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred, columns = category_names)\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train using Grid Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time  = datetime.datetime.now()\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenize)), #create the CountVectorizer object\n",
    "    ('tfidf', TfidfTransformer()), #create Tfidftransformer object    \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier())) #create the Classifier object\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf__estimator__class_weight',\n",
       " 'vectorizer__ngram_range',\n",
       " 'vectorizer__max_features',\n",
       " 'clf__estimator__max_leaf_nodes',\n",
       " 'clf__estimator__criterion',\n",
       " 'vectorizer__max_df',\n",
       " 'tfidf__use_idf',\n",
       " 'clf__estimator__n_jobs',\n",
       " 'clf__n_jobs',\n",
       " 'vectorizer__encoding',\n",
       " 'clf__estimator__random_state',\n",
       " 'clf__estimator__min_impurity_split',\n",
       " 'tfidf__smooth_idf',\n",
       " 'tfidf__sublinear_tf',\n",
       " 'clf',\n",
       " 'clf__estimator',\n",
       " 'vectorizer__input',\n",
       " 'clf__estimator__min_weight_fraction_leaf',\n",
       " 'memory',\n",
       " 'clf__estimator__oob_score',\n",
       " 'vectorizer__preprocessor',\n",
       " 'vectorizer',\n",
       " 'clf__estimator__bootstrap',\n",
       " 'vectorizer__min_df',\n",
       " 'clf__estimator__min_samples_split',\n",
       " 'vectorizer__token_pattern',\n",
       " 'vectorizer__analyzer',\n",
       " 'vectorizer__binary',\n",
       " 'vectorizer__lowercase',\n",
       " 'clf__estimator__min_samples_leaf',\n",
       " 'vectorizer__tokenizer',\n",
       " 'clf__estimator__max_depth',\n",
       " 'tfidf__norm',\n",
       " 'vectorizer__stop_words',\n",
       " 'vectorizer__vocabulary',\n",
       " 'vectorizer__dtype',\n",
       " 'clf__estimator__verbose',\n",
       " 'clf__estimator__warm_start',\n",
       " 'tfidf',\n",
       " 'clf__estimator__max_features',\n",
       " 'vectorizer__decode_error',\n",
       " 'steps',\n",
       " 'vectorizer__strip_accents',\n",
       " 'clf__estimator__min_impurity_decrease',\n",
       " 'clf__estimator__n_estimators']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {    \n",
    "        'tfidf__use_idf': (True, False), \n",
    "        'clf__estimator__n_estimators': [50, 100],\n",
    "        'clf__estimator__min_samples_split': [2,4] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(pipeline, param_grid=parameters, cv=5,verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "C:\\Users\\Essam\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 61.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'tfidf__use_idf': (True, False), 'clf__estimator__n_estimators': [50, 100], 'clf__estimator__min_samples_split': [2, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training of Pipeline Done..., Time: 70', 'minutes')\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "print ('Training of Pipeline Done..., Time: %d' % ((end_time - start_time).seconds/60),'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Best Cross Validation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_score_\n",
    "best_parameters=grid_cv.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_jobs=None),\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__n_jobs': None,\n",
       " 'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "           dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x000000000E62E048>,\n",
       "           vocabulary=None)),\n",
       "  ('tfidf', TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "            use_idf=False)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "               oob_score=False, random_state=None, verbose=0,\n",
       "               warm_start=False),\n",
       "              n_jobs=None))],\n",
       " 'tfidf': TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "          use_idf=False),\n",
       " 'tfidf__norm': u'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vectorizer': CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x000000000E62E048>,\n",
       "         vocabulary=None),\n",
       " 'vectorizer__analyzer': u'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': u'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': u'utf-8',\n",
       " 'vectorizer__input': u'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': <function __main__.tokenize>,\n",
       " 'vectorizer__vocabulary': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__estimator__min_samples_split: 2\n",
      "\tclf__estimator__n_estimators: 100\n",
      "\ttfidf__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "#https://www.programcreek.com/python/example/91151/sklearn.model_selection.GridSearchCV\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using Best Cross Validation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenize)), #create the CountVectorizer object\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)), #create Tfidftransformer object    \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(min_samples_split= 4,n_estimators= 100),\\\n",
    "        n_jobs=-1)) #create the Classifier object\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...ob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=-1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model using Best Cross Validation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the classifier\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert prediction numpy into dataframe\n",
    "y_test=pd.DataFrame(data=y_test,columns=Y.columns)\n",
    "y_pred=pd.DataFrame(data=y_pred,columns=Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      4349\n",
      "           1       0.90      0.43      0.58       895\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5244\n",
      "   macro avg       0.90      0.71      0.76      5244\n",
      "weighted avg       0.89      0.89      0.88      5244\n",
      "\n",
      "_____________________________________________________\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5218\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      3113\n",
      "           1       0.78      0.62      0.69      2131\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5244\n",
      "   macro avg       0.77      0.75      0.75      5244\n",
      "weighted avg       0.77      0.77      0.77      5244\n",
      "\n",
      "_____________________________________________________\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4822\n",
      "           1       0.69      0.08      0.14       422\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      5244\n",
      "   macro avg       0.81      0.54      0.55      5244\n",
      "weighted avg       0.91      0.92      0.89      5244\n",
      "\n",
      "_____________________________________________________\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4974\n",
      "           1       0.73      0.03      0.06       270\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.84      0.51      0.52      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5117\n",
      "           1       0.83      0.04      0.08       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.91      0.52      0.53      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5156\n",
      "           1       0.50      0.01      0.02        88\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.74      0.51      0.51      5244\n",
      "weighted avg       0.98      0.98      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5089\n",
      "           1       0.75      0.06      0.11       155\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.86      0.53      0.55      5244\n",
      "weighted avg       0.97      0.97      0.96      5244\n",
      "\n",
      "_____________________________________________________\n",
      "child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5244\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       1.00      1.00      1.00      5244\n",
      "weighted avg       1.00      1.00      1.00      5244\n",
      "\n",
      "_____________________________________________________\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4905\n",
      "           1       0.89      0.22      0.36       339\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.92      0.61      0.67      5244\n",
      "weighted avg       0.95      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4649\n",
      "           1       0.90      0.40      0.55       595\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5244\n",
      "   macro avg       0.91      0.70      0.76      5244\n",
      "weighted avg       0.92      0.93      0.91      5244\n",
      "\n",
      "_____________________________________________________\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4774\n",
      "           1       0.87      0.20      0.33       470\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5244\n",
      "   macro avg       0.90      0.60      0.64      5244\n",
      "weighted avg       0.92      0.93      0.90      5244\n",
      "\n",
      "_____________________________________________________\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5171\n",
      "           1       1.00      0.04      0.08        73\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.99      0.52      0.54      5244\n",
      "weighted avg       0.99      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5140\n",
      "           1       0.88      0.07      0.12       104\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.93      0.53      0.56      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5184\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5073\n",
      "           1       0.67      0.01      0.02       171\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.82      0.51      0.50      5244\n",
      "weighted avg       0.96      0.97      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5007\n",
      "           1       0.83      0.10      0.18       237\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.89      0.55      0.58      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4549\n",
      "           1       0.73      0.01      0.02       695\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5244\n",
      "   macro avg       0.80      0.51      0.48      5244\n",
      "weighted avg       0.85      0.87      0.81      5244\n",
      "\n",
      "_____________________________________________________\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4916\n",
      "           1       0.00      0.00      0.00       328\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.47      0.50      0.48      5244\n",
      "weighted avg       0.88      0.94      0.91      5244\n",
      "\n",
      "_____________________________________________________\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5004\n",
      "           1       0.83      0.08      0.15       240\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.90      0.54      0.56      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4977\n",
      "           1       0.92      0.04      0.09       267\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.94      0.52      0.53      5244\n",
      "weighted avg       0.95      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5122\n",
      "           1       1.00      0.02      0.03       122\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.99      0.51      0.51      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5212\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5198\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5222\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5177\n",
      "           1       0.00      0.00      0.00        67\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.97      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5021\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.48      0.50      0.49      5244\n",
      "weighted avg       0.92      0.96      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      3806\n",
      "           1       0.86      0.63      0.73      1438\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5244\n",
      "   macro avg       0.87      0.80      0.82      5244\n",
      "weighted avg       0.87      0.87      0.86      5244\n",
      "\n",
      "_____________________________________________________\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4833\n",
      "           1       0.91      0.36      0.51       411\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.93      0.68      0.74      5244\n",
      "weighted avg       0.94      0.95      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4758\n",
      "           1       0.76      0.45      0.57       486\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.85      0.72      0.77      5244\n",
      "weighted avg       0.93      0.94      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5191\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4766\n",
      "           1       0.88      0.72      0.79       478\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.92      0.85      0.89      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "_____________________________________________________\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5127\n",
      "           1       0.77      0.15      0.24       117\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.88      0.57      0.62      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4968\n",
      "           1       1.00      0.01      0.03       276\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.97      0.51      0.50      5244\n",
      "weighted avg       0.95      0.95      0.92      5244\n",
      "\n",
      "_____________________________________________________\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      4223\n",
      "           1       0.85      0.33      0.47      1021\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5244\n",
      "   macro avg       0.85      0.66      0.69      5244\n",
      "weighted avg       0.86      0.86      0.83      5244\n",
      "\n",
      "_____________________________________________________\n",
      "direct\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      3067\n",
      "           1       0.93      0.96      0.95      2177\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.95      0.96      0.95      5244\n",
      "weighted avg       0.96      0.96      0.96      5244\n",
      "\n",
      "_____________________________________________________\n",
      "news\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      2670\n",
      "           1       0.98      0.96      0.97      2574\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.97      0.97      0.97      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "results_dic2={}\n",
    "\n",
    "for column in y_pred.columns:\n",
    "    print(column)\n",
    "    print(classification_report(y_test[column], y_pred[column]))\n",
    "    print('_____________________________________________________')\n",
    "    \n",
    "    results_dic2[column]=classification_report(y_test[column], y_pred[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train using Grid Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time  = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenize)), #create the CountVectorizer object\n",
    "    ('tfidf', TfidfTransformer()), #create Tfidftransformer object    \n",
    "    ('clf', MultiOutputClassifier(OneVsRestClassifier(LinearSVC()))) #create the Classifier object\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultiOutputClassifier(estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       "           n_jobs=None),\n",
       "            n_jobs=None),\n",
       " 'clf__estimator': OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       "           n_jobs=None),\n",
       " 'clf__estimator__estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'clf__estimator__estimator__C': 1.0,\n",
       " 'clf__estimator__estimator__class_weight': None,\n",
       " 'clf__estimator__estimator__dual': True,\n",
       " 'clf__estimator__estimator__fit_intercept': True,\n",
       " 'clf__estimator__estimator__intercept_scaling': 1,\n",
       " 'clf__estimator__estimator__loss': 'squared_hinge',\n",
       " 'clf__estimator__estimator__max_iter': 1000,\n",
       " 'clf__estimator__estimator__multi_class': 'ovr',\n",
       " 'clf__estimator__estimator__penalty': 'l2',\n",
       " 'clf__estimator__estimator__random_state': None,\n",
       " 'clf__estimator__estimator__tol': 0.0001,\n",
       " 'clf__estimator__estimator__verbose': 0,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__n_jobs': None,\n",
       " 'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "           dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x000000000E62E048>,\n",
       "           vocabulary=None)),\n",
       "  ('tfidf', TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "            use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "        verbose=0),\n",
       "             n_jobs=None),\n",
       "              n_jobs=None))],\n",
       " 'tfidf': TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "          use_idf=True),\n",
       " 'tfidf__norm': u'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vectorizer': CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x000000000E62E048>,\n",
       "         vocabulary=None),\n",
       " 'vectorizer__analyzer': u'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': u'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': u'utf-8',\n",
       " 'vectorizer__input': u'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': <function __main__.tokenize>,\n",
       " 'vectorizer__vocabulary': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {    \n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'vectorizer__max_df': [0.8,0.9,1.0],\n",
    "        'vectorizer__ngram_range': ((1, 1),(1,2)),\n",
    "        'clf__estimator__estimator__C': [0.01,0.1, 1,10,100]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(pipeline, param_grid=parameters, cv=5,verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 53.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 66.7min finished\n",
      "C:\\Users\\Essam\\Anaconda2\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=None),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'clf__estimator__estimator__C': [0.01, 0.1, 1, 10, 100], 'vectorizer__ngram_range': ((1, 1), (1, 2)), 'tfidf__use_idf': (True, False), 'vectorizer__max_df': [0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training of Pipeline Done..., Time: 67', 'minutes')\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "print ('Training of Pipeline Done..., Time: %d' % ((end_time - start_time).seconds/60),'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Identify Best Cross Validation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4029658592408926"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters=grid_cv.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultiOutputClassifier(estimator=OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       "           n_jobs=None),\n",
       "            n_jobs=None),\n",
       " 'clf__estimator': OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       "           n_jobs=None),\n",
       " 'clf__estimator__estimator': LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'clf__estimator__estimator__C': 1,\n",
       " 'clf__estimator__estimator__class_weight': None,\n",
       " 'clf__estimator__estimator__dual': True,\n",
       " 'clf__estimator__estimator__fit_intercept': True,\n",
       " 'clf__estimator__estimator__intercept_scaling': 1,\n",
       " 'clf__estimator__estimator__loss': 'squared_hinge',\n",
       " 'clf__estimator__estimator__max_iter': 1000,\n",
       " 'clf__estimator__estimator__multi_class': 'ovr',\n",
       " 'clf__estimator__estimator__penalty': 'l2',\n",
       " 'clf__estimator__estimator__random_state': None,\n",
       " 'clf__estimator__estimator__tol': 0.0001,\n",
       " 'clf__estimator__estimator__verbose': 0,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__n_jobs': None,\n",
       " 'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "           dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "           lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x000000000E62E048>,\n",
       "           vocabulary=None)),\n",
       "  ('tfidf', TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "            use_idf=False)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "        verbose=0),\n",
       "             n_jobs=None),\n",
       "              n_jobs=None))],\n",
       " 'tfidf': TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "          use_idf=False),\n",
       " 'tfidf__norm': u'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vectorizer': CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x000000000E62E048>,\n",
       "         vocabulary=None),\n",
       " 'vectorizer__analyzer': u'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': u'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': u'utf-8',\n",
       " 'vectorizer__input': u'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 0.8,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': <function __main__.tokenize>,\n",
       " 'vectorizer__vocabulary': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__estimator__estimator__C: 1\n",
      "\ttfidf__use_idf: False\n",
      "\tvectorizer__max_df: 0.8\n",
      "\tvectorizer__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#https://www.programcreek.com/python/example/91151/sklearn.model_selection.GridSearchCV\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using Best Cross Validation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=None),\n",
       "           n_jobs=None))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the classifier\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert prediction numpy into dataframe\n",
    "y_test=pd.DataFrame(data=y_test,columns=Y.columns)\n",
    "y_pred=pd.DataFrame(data=y_pred,columns=Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      4349\n",
      "           1       0.78      0.60      0.68       895\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5244\n",
      "   macro avg       0.85      0.78      0.81      5244\n",
      "weighted avg       0.90      0.90      0.90      5244\n",
      "\n",
      "_____________________________________________________\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5218\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      3113\n",
      "           1       0.72      0.70      0.71      2131\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5244\n",
      "   macro avg       0.76      0.76      0.76      5244\n",
      "weighted avg       0.77      0.77      0.77      5244\n",
      "\n",
      "_____________________________________________________\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4822\n",
      "           1       0.58      0.28      0.38       422\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5244\n",
      "   macro avg       0.76      0.63      0.67      5244\n",
      "weighted avg       0.91      0.93      0.91      5244\n",
      "\n",
      "_____________________________________________________\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      4974\n",
      "           1       0.65      0.27      0.38       270\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.81      0.63      0.68      5244\n",
      "weighted avg       0.95      0.95      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5117\n",
      "           1       0.72      0.17      0.27       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.85      0.58      0.63      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5156\n",
      "           1       0.40      0.02      0.04        88\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.69      0.51      0.52      5244\n",
      "weighted avg       0.97      0.98      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5089\n",
      "           1       0.55      0.28      0.37       155\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.76      0.64      0.68      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5244\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       1.00      1.00      1.00      5244\n",
      "weighted avg       1.00      1.00      1.00      5244\n",
      "\n",
      "_____________________________________________________\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4905\n",
      "           1       0.73      0.57      0.64       339\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.85      0.78      0.81      5244\n",
      "weighted avg       0.96      0.96      0.96      5244\n",
      "\n",
      "_____________________________________________________\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4649\n",
      "           1       0.83      0.69      0.75       595\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.89      0.84      0.86      5244\n",
      "weighted avg       0.95      0.95      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4774\n",
      "           1       0.79      0.59      0.68       470\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.88      0.79      0.82      5244\n",
      "weighted avg       0.95      0.95      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5171\n",
      "           1       0.73      0.33      0.45        73\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.86      0.66      0.72      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5140\n",
      "           1       0.48      0.22      0.30       104\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.73      0.61      0.65      5244\n",
      "weighted avg       0.97      0.98      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5184\n",
      "           1       0.82      0.15      0.25        60\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.90      0.57      0.62      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5073\n",
      "           1       0.64      0.27      0.38       171\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.81      0.63      0.68      5244\n",
      "weighted avg       0.96      0.97      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5007\n",
      "           1       0.81      0.47      0.59       237\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.89      0.73      0.79      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      4549\n",
      "           1       0.44      0.18      0.25       695\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5244\n",
      "   macro avg       0.66      0.57      0.59      5244\n",
      "weighted avg       0.83      0.86      0.83      5244\n",
      "\n",
      "_____________________________________________________\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      4916\n",
      "           1       0.29      0.07      0.11       328\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5244\n",
      "   macro avg       0.62      0.53      0.54      5244\n",
      "weighted avg       0.90      0.93      0.91      5244\n",
      "\n",
      "_____________________________________________________\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5004\n",
      "           1       0.68      0.19      0.29       240\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.82      0.59      0.64      5244\n",
      "weighted avg       0.95      0.96      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4977\n",
      "           1       0.72      0.35      0.47       267\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.84      0.67      0.73      5244\n",
      "weighted avg       0.95      0.96      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5122\n",
      "           1       0.69      0.20      0.32       122\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.84      0.60      0.65      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5212\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5198\n",
      "           1       0.29      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.64      0.52      0.54      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5222\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5177\n",
      "           1       0.50      0.03      0.06        67\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.74      0.51      0.52      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5021\n",
      "           1       0.20      0.02      0.04       223\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.58      0.51      0.51      5244\n",
      "weighted avg       0.93      0.95      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      3806\n",
      "           1       0.81      0.71      0.76      1438\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5244\n",
      "   macro avg       0.85      0.83      0.84      5244\n",
      "weighted avg       0.87      0.88      0.87      5244\n",
      "\n",
      "_____________________________________________________\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      4833\n",
      "           1       0.85      0.55      0.67       411\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.91      0.77      0.82      5244\n",
      "weighted avg       0.95      0.96      0.95      5244\n",
      "\n",
      "_____________________________________________________\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4758\n",
      "           1       0.72      0.60      0.66       486\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.84      0.79      0.81      5244\n",
      "weighted avg       0.94      0.94      0.94      5244\n",
      "\n",
      "_____________________________________________________\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5191\n",
      "           1       0.72      0.25      0.37        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.86      0.62      0.68      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "_____________________________________________________\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4766\n",
      "           1       0.88      0.73      0.80       478\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.93      0.86      0.89      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5127\n",
      "           1       0.76      0.32      0.45       117\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.87      0.66      0.72      5244\n",
      "weighted avg       0.98      0.98      0.98      5244\n",
      "\n",
      "_____________________________________________________\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4968\n",
      "           1       0.57      0.14      0.23       276\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.76      0.57      0.60      5244\n",
      "weighted avg       0.93      0.95      0.93      5244\n",
      "\n",
      "_____________________________________________________\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      4223\n",
      "           1       0.70      0.51      0.59      1021\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5244\n",
      "   macro avg       0.80      0.73      0.76      5244\n",
      "weighted avg       0.85      0.86      0.85      5244\n",
      "\n",
      "_____________________________________________________\n",
      "direct\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3067\n",
      "           1       0.97      0.95      0.96      2177\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.97      0.97      0.97      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "_____________________________________________________\n",
      "news\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2670\n",
      "           1       0.97      0.98      0.98      2574\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.98      0.98      0.98      5244\n",
      "weighted avg       0.98      0.98      0.98      5244\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "results_dic={}\n",
    "\n",
    "for column in y_pred.columns:\n",
    "    print(column)\n",
    "    print(classification_report(y_test[column], y_pred[column]))\n",
    "    print('_____________________________________________________')\n",
    "    \n",
    "    results_dic[column]=classification_report(y_test[column], y_pred[column],output_dict=True)['weighted avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aid_centers': {'f1-score': 0.9815936783760634,\n",
       "  'precision': 0.981365653804275,\n",
       "  'recall': 0.9872234935163997,\n",
       "  'support': 5244L},\n",
       " 'aid_related': {'f1-score': 0.7688370046921121,\n",
       "  'precision': 0.7684795518969728,\n",
       "  'recall': 0.7694508009153318,\n",
       "  'support': 5244L},\n",
       " 'buildings': {'f1-score': 0.9535387159848336,\n",
       "  'precision': 0.9537940639048424,\n",
       "  'recall': 0.9601449275362319,\n",
       "  'support': 5244L},\n",
       " 'child_alone': {'f1-score': 1.0,\n",
       "  'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'support': 5244L},\n",
       " 'clothing': {'f1-score': 0.9868742058766515,\n",
       "  'precision': 0.9869311663832321,\n",
       "  'recall': 0.9889397406559878,\n",
       "  'support': 5244L},\n",
       " 'cold': {'f1-score': 0.9789206080381652,\n",
       "  'precision': 0.9794801867862285,\n",
       "  'recall': 0.9824561403508771,\n",
       "  'support': 5244L},\n",
       " 'death': {'f1-score': 0.9672827189247415,\n",
       "  'precision': 0.9678659610392815,\n",
       "  'recall': 0.9710144927536232,\n",
       "  'support': 5244L},\n",
       " 'direct': {'f1-score': 0.9690553006348562,\n",
       "  'precision': 0.9691710272974121,\n",
       "  'recall': 0.9691075514874142,\n",
       "  'support': 5244L},\n",
       " 'direct_report': {'f1-score': 0.85462311723095,\n",
       "  'precision': 0.8533164220768278,\n",
       "  'recall': 0.8630816170861938,\n",
       "  'support': 5244L},\n",
       " 'earthquake': {'f1-score': 0.9652626323286547,\n",
       "  'precision': 0.9652111051173049,\n",
       "  'recall': 0.9666285278413425,\n",
       "  'support': 5244L},\n",
       " 'electricity': {'f1-score': 0.9738858045980765,\n",
       "  'precision': 0.9746994639083294,\n",
       "  'recall': 0.9794050343249427,\n",
       "  'support': 5244L},\n",
       " 'fire': {'f1-score': 0.9893180870108891,\n",
       "  'precision': 0.9896158789264768,\n",
       "  'recall': 0.9914187643020596,\n",
       "  'support': 5244L},\n",
       " 'floods': {'f1-score': 0.9534809566283805,\n",
       "  'precision': 0.9546645781868546,\n",
       "  'recall': 0.9576659038901602,\n",
       "  'support': 5244L},\n",
       " 'food': {'f1-score': 0.9467374850771038,\n",
       "  'precision': 0.9462461105472826,\n",
       "  'recall': 0.9487032799389779,\n",
       "  'support': 5244L},\n",
       " 'hospitals': {'f1-score': 0.987235557771847,\n",
       "  'precision': 0.9854062787290931,\n",
       "  'recall': 0.9906559877955758,\n",
       "  'support': 5244L},\n",
       " 'infrastructure_related': {'f1-score': 0.910951485609797,\n",
       "  'precision': 0.9003046236265253,\n",
       "  'recall': 0.9311594202898551,\n",
       "  'support': 5244L},\n",
       " 'medical_help': {'f1-score': 0.913792793515605,\n",
       "  'precision': 0.9110944754068918,\n",
       "  'recall': 0.9260106788710908,\n",
       "  'support': 5244L},\n",
       " 'medical_products': {'f1-score': 0.9458778827111136,\n",
       "  'precision': 0.9456327040271828,\n",
       "  'recall': 0.9549961861174676,\n",
       "  'support': 5244L},\n",
       " 'military': {'f1-score': 0.9675972922786594,\n",
       "  'precision': 0.9658394588836285,\n",
       "  'recall': 0.9719679633867276,\n",
       "  'support': 5244L},\n",
       " 'missing_people': {'f1-score': 0.9864294278445405,\n",
       "  'precision': 0.9882853652615256,\n",
       "  'recall': 0.9898932112890922,\n",
       "  'support': 5244L},\n",
       " 'money': {'f1-score': 0.9761176269857575,\n",
       "  'precision': 0.9743909825606624,\n",
       "  'recall': 0.9797864225781846,\n",
       "  'support': 5244L},\n",
       " 'news': {'f1-score': 0.9788343861888782,\n",
       "  'precision': 0.9788877202683096,\n",
       "  'recall': 0.9788329519450801,\n",
       "  'support': 5244L},\n",
       " 'offer': {'f1-score': 0.9925690898928685,\n",
       "  'precision': 0.9901084876486643,\n",
       "  'recall': 0.9950419527078566,\n",
       "  'support': 5244L},\n",
       " 'other_aid': {'f1-score': 0.8343544849689465,\n",
       "  'precision': 0.8254701414888039,\n",
       "  'recall': 0.860602593440122,\n",
       "  'support': 5244L},\n",
       " 'other_infrastructure': {'f1-score': 0.9369361006953418,\n",
       "  'precision': 0.9259859934999575,\n",
       "  'recall': 0.9546147978642258,\n",
       "  'support': 5244L},\n",
       " 'other_weather': {'f1-score': 0.9344600542880199,\n",
       "  'precision': 0.9341758341667423,\n",
       "  'recall': 0.9492753623188406,\n",
       "  'support': 5244L},\n",
       " 'refugees': {'f1-score': 0.9654787025445035,\n",
       "  'precision': 0.9648441440532635,\n",
       "  'recall': 0.971205186880244,\n",
       "  'support': 5244L},\n",
       " 'request': {'f1-score': 0.896796170244248,\n",
       "  'precision': 0.8964855128222285,\n",
       "  'recall': 0.9021739130434783,\n",
       "  'support': 5244L},\n",
       " 'search_and_rescue': {'f1-score': 0.9715356518113678,\n",
       "  'precision': 0.9734854049485326,\n",
       "  'recall': 0.9782608695652174,\n",
       "  'support': 5244L},\n",
       " 'security': {'f1-score': 0.9755225517337671,\n",
       "  'precision': 0.9737914709676837,\n",
       "  'recall': 0.9830282227307399,\n",
       "  'support': 5244L},\n",
       " 'shelter': {'f1-score': 0.946049281496521,\n",
       "  'precision': 0.9456155674676815,\n",
       "  'recall': 0.9494660564454614,\n",
       "  'support': 5244L},\n",
       " 'shops': {'f1-score': 0.9937115031449043,\n",
       "  'precision': 0.9916270587256454,\n",
       "  'recall': 0.9958047292143402,\n",
       "  'support': 5244L},\n",
       " 'storm': {'f1-score': 0.9395050649204054,\n",
       "  'precision': 0.9382536550455561,\n",
       "  'recall': 0.9418382913806255,\n",
       "  'support': 5244L},\n",
       " 'tools': {'f1-score': 0.9908560196606082,\n",
       "  'precision': 0.9878328128881884,\n",
       "  'recall': 0.9938977879481312,\n",
       "  'support': 5244L},\n",
       " 'transport': {'f1-score': 0.9474511527829789,\n",
       "  'precision': 0.9495021141677078,\n",
       "  'recall': 0.9588100686498856,\n",
       "  'support': 5244L},\n",
       " 'water': {'f1-score': 0.9566065947703783,\n",
       "  'precision': 0.9556249754583134,\n",
       "  'recall': 0.9590007627765065,\n",
       "  'support': 5244L},\n",
       " 'weather_related': {'f1-score': 0.8737657329636248,\n",
       "  'precision': 0.8736182106290113,\n",
       "  'recall': 0.8764302059496567,\n",
       "  'support': 5244L}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('classifier.pkl','wb')\n",
    "pickle.dump(pipeline, pickle_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
