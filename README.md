# Disaster_Response_Pipeline
Udacity Data Science Nano-degree Porject

## Summary
This Project is the third project of Data Science Nanodegree Program by Udacity. The datasets contains pre-labelled tweet and messages from real-life disaster. The aim of the project is to build a Natural Language Processing tool that categorize messages.
The goal of this project to develop a model and platform to predict which category belong the information got from people in the middle of a disaster.

The project has three sections:

-Data Processing, ETL Pipeline model to extract data from source, clean data and save them into database.
-Machine Learning Pipeline model to train and evaluate the applied model.
-Web App to visualize model results.


## Installation
Python standard configuration
Python 3.5+ 
Machine Learning Libraries: NumPy, SciPy, Pandas, Sciki-Learn
Natural Language Process Libraries: NLTK
SQLlite Database Libraqries: SQLalchemy
Web App and Data Visualization: Flask, Plotly
The following packages need to be installed for nltk:
punkt
wordnet

## Instructions:
Run the following commands in the project's root directory to set up your database and model.

To run ETL pipeline that cleans data and stores in database:

$ python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db

To run ML pipeline that trains classifier and saves model:

$ python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl
Run the following command: model in the app's directory to run your web app:

$ python app/run.py
Go to: http://0.0.0.0:3001/


## Explanation of the files in the repository
* **process_data.py**: This python code which takes two input csv files message and categories and generate an SQLite database containing a merged and cleaned this data.
* **train_classifier.py**: This python code which takes input SQLite database generated by process_data.py and ML file to generate a file used to visulize the results.
* **ETL Pipeline Preparation.ipynb**: Jupyter template file was provided by Udacity to help develop process_data.py file.
* **ML Pipeline Preparation.ipynb**: Jupyter template file was provided by Udacity to help develop train_classifier.py 


## Licensing, Authors, Acknowledgements
Code templates and data were provided by Udacity [Udacity Data Scientist Nanodegree](https://www.udacity.com/course/data-scientist-nanodegree--nd025). 
